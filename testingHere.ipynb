{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea12369",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685884b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import pydicom\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee6e0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BraTS21ID  MGMT_value\n",
       "0          0           1\n",
       "1          2           1\n",
       "2          3           0\n",
       "3          5           1\n",
       "4          6           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Files:\n",
    "\n",
    "data_dir = \"../train\"\n",
    "patients = os.listdir(data_dir)\n",
    "labels_df = pd.read_csv(\"../train_labels.csv\")\n",
    "label=labels_df.loc[:,'MGMT_value']\n",
    "scan = [\"FLAIR\",\"T1w\",\"T1wCE\",\"T2w\"]\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa72880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 1 (512, 512)\n",
      "129 1 (512, 512)\n",
      "129 0 (512, 512)\n",
      "400 1 (512, 512)\n",
      "129 1 (512, 512)\n",
      "168 1 (512, 512)\n",
      "240 0 (512, 512)\n",
      "129 1 (512, 512)\n",
      "400 1 (512, 512)\n",
      "216 1 (512, 512)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for patient in patients[:10]:\n",
    "#     label = labels_df._get_value(patient,\"\")\n",
    "    path = data_dir + '/'+ patient + \"/\" + scan[0]\n",
    "    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[0]))\n",
    "    print(len(slices),label[i],slices[i].pixel_array.shape)\n",
    "    i+=1\n",
    "#     print(slices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfcdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753a9b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "#FUNCTIONS WE USE:\n",
    "l=[1,2,3,4,5,6,7,8,9]\n",
    "def chunk(l,n):\n",
    "    for i in range(0,len(l),n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "print(list(chunk(l,3)))\n",
    "        \n",
    "        \n",
    "def mean(l):\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "def resize(layer,HM_slices):\n",
    "    if(len(layer)<HM_slices and HM_slices-len(layer)>1):\n",
    "        layer.append(layer[-1])\n",
    "        return resize(layer,HM_slices)\n",
    "    elif(len(layer)<HM_slices and HM_slices-len(layer)==1):\n",
    "        layer.append(layer[-1])\n",
    "        return layer\n",
    "    else:\n",
    "        return layer\n",
    "    \n",
    "    \n",
    "    \n",
    "def process_data(patients, label_df, IMG_PX_SIZE = 50,HM_slices=20, visual=False, i=0):\n",
    "    path = data_dir + '/'+ patient + \"/\" + scan[scan_type]\n",
    "    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[0]))\n",
    "    i+=1\n",
    "\n",
    "       \n",
    "    new_slices = []\n",
    "\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array),(IMG_PX_SIZE,IMG_PX_SIZE)) for each_slice in slices]\n",
    "\n",
    "    chunk_sizes =  math.ceil(len(slices)/HM_slices)\n",
    "\n",
    "    for slice_chunk in chunk(slices, chunk_sizes):\n",
    "            slice_chunk = list(map(mean,zip(*slice_chunk)))\n",
    "            new_slices.append(slice_chunk)\n",
    "\n",
    "    new_slices=resize(new_slices,HM_slices)\n",
    "    len(new_slices)\n",
    "        \n",
    "    if visual:\n",
    "        fig = plt.figure()\n",
    "        for num,each_slice in enumerate(new_slices):\n",
    "            y = fig.add_subplot(4,5,num+1)\n",
    "            y.imshow(each_slice,cmap='gray')\n",
    "        #         y.imshow(each_slice)\n",
    "        plt.show()\n",
    "            \n",
    "    if label[i]==1: label[i]=np.array([0,1])\n",
    "    elif label[i]==0: label[i]=np.array([1,0])\n",
    "\n",
    "    return np.array(new_slices), label [i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d8abc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am done\n",
      "50 200\n"
     ]
    }
   ],
   "source": [
    "IMG_PX_SIZE = 50\n",
    "HM_slices=20\n",
    "i=0\n",
    "j=0 \n",
    "much_data=[]\n",
    "ps=[]\n",
    "for patient in patients[100:150]:\n",
    "    for scan_type in range(4):\n",
    "        path = data_dir + '/'+ patient + \"/\" + scan[scan_type]\n",
    "        slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "        slices.sort(key = lambda x: int(x.ImagePositionPatient[0]))\n",
    "    #     print(len(slices),label[i],slices[i].pixel_array.shape)\n",
    "        i+=1\n",
    "\n",
    "       \n",
    "        new_slices = []\n",
    "\n",
    "        slices = [cv2.resize(np.array(each_slice.pixel_array),(IMG_PX_SIZE,IMG_PX_SIZE)) for each_slice in slices]\n",
    "\n",
    "        chunk_sizes =  math.ceil(len(slices)/HM_slices)\n",
    "    #     print(chunk_sizes)\n",
    "\n",
    "        for slice_chunk in chunk(slices, chunk_sizes):\n",
    "    #         print(slice_chunk)\n",
    "            slice_chunk = list(map(mean,zip(*slice_chunk)))\n",
    "            new_slices.append(slice_chunk)\n",
    "\n",
    "        new_slices=resize(new_slices,HM_slices)\n",
    "#         print(len(new_slices))\n",
    "        \n",
    "#         if label[i]==1: label[i]=np.vectorize([0,1])\n",
    "#         elif label[i]==0: label[i]=np.vectorize([1,0])\n",
    "\n",
    "\n",
    "#         fig = plt.figure()\n",
    "#         for num,each_slice in enumerate(new_slices):\n",
    "#             y = fig.add_subplot(4,5,num+1)\n",
    "#     #         new_image = cv2.resize(np.array(each_slice.pixel_array),(IMG_PX_SIZE,IMG_PX_SIZE))\n",
    "#             y.imshow(each_slice,cmap='gray')\n",
    "#     #         y.imshow(each_slice)\n",
    "        ps.append(new_slices)\n",
    "    much_data.append(ps)\n",
    "# plt.show()\n",
    "print('I am done')\n",
    "print(len(much_data),len(ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7cdb78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from scipy.ndimage import zoom\\nIMG_PX_SIZE = 250\\ni=0\\nj=0 \\nfor patient in patients[:1]:\\n    path = data_dir + \\'/\\'+ patient + \"/\" + scan[0]\\n    slices = [pydicom.read_file(path + \\'/\\' + s) for s in os.listdir(path)]\\n    slices.sort(key = lambda x: int(x.ImagePositionPatient[0]))\\n    i+=1\\n    print(len(slices))\\n    HM_slices=20\\n#     new_slices = []\\n    factor = len(slices)/20\\n    new_slices = zoom(np.array(slices),(1,1,factor))\\n    print(type(np.array(slices)))\\n    print(np.array(slices).shape)\\n      \\n#     for slice_chunk in chunk(slices, chunk_sizes):\\n#         slice_chunk = list(map(mean,zip(*slice_chunk)))\\n#         new_slices.append(slice_chunk)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from scipy.ndimage import zoom\n",
    "IMG_PX_SIZE = 250\n",
    "i=0\n",
    "j=0 \n",
    "for patient in patients[:1]:\n",
    "    path = data_dir + '/'+ patient + \"/\" + scan[0]\n",
    "    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[0]))\n",
    "    i+=1\n",
    "    print(len(slices))\n",
    "    HM_slices=20\n",
    "#     new_slices = []\n",
    "    factor = len(slices)/20\n",
    "    new_slices = zoom(np.array(slices),(1,1,factor))\n",
    "    print(type(np.array(slices)))\n",
    "    print(np.array(slices).shape)\n",
    "      \n",
    "#     for slice_chunk in chunk(slices, chunk_sizes):\n",
    "#         slice_chunk = list(map(mean,zip(*slice_chunk)))\n",
    "#         new_slices.append(slice_chunk)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 14, 14, 14, 32)    2624      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 7, 7, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 7, 7, 7, 32)       128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 7, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 5, 5, 5, 64)       55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 2, 2, 2, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 2, 2, 64)       256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 2, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 258,058\n",
      "Trainable params: 257,866\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_shape = (16, 16, 16, 3)\n",
    "#MODEL\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization(center=True, scale=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization(center=True, scale=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Fit data to model\n",
    "history = model.fit(much_data, label[100:150],\n",
    "            batch_size=128,\n",
    "            epochs=40,\n",
    "            verbose=1,\n",
    "            validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cee19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "580    1\n",
       "581    1\n",
       "582    1\n",
       "583    0\n",
       "584    0\n",
       "Name: MGMT_value, Length: 585, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(new_slices)\n",
    "label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf71b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
